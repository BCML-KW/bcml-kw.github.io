---
title: 'Reinforcement Learning'
summary: 'Sample-efficient policy learning for neuromorphic robots, digital therapeutics, and adaptive decision systems.'
description: 'We blend classical RL theory with neuromorphic hardware research to build controllers that learn from sparse demonstrations yet operate safely on physical devices.'
view: 2
---

{{< research_area_highlight section="project/reinforcement-learning" title="Reinforcement Learning" >}}
<p>Policy learning that blends neuromorphic hardware, simulators, and human-in-the-loop safety constraints for real-world actuation.</p>
<ul>
	<li>Reward-modulated STDP controllers for spiking and analog robots</li>
	<li>Safe RL protocols for medical, assistive, and rehab devices</li>
	<li>Sim-to-real transfer stacks with telemetry-aware monitoring</li>
</ul>
{{< /research_area_highlight >}}

## Research Area Overview

Our reinforcement learning (RL) portfolio spans curriculum design, imitation learning, and real-world deployment. We develop agents that can reason over biosignals and sensory data, then act through robotic manipulators, rehabilitation devices, or clinical decision-support workflows.

### Focus Topics

- Reward-modulated spike-timing-dependent plasticity (R-STDP) for neuromorphic policies
- Safe RL strategies that respect human-in-the-loop constraints
- Hybrid RL + control architectures for medical and service robots
- Sim-to-real pipelines with photorealistic simulation assets
